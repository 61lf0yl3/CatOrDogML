# CatOrDogML
on Google's Colab, train a neural network on differentiating between a cat pic and dog pic, then use the trained network to classify a new (cat-like or dog-like) pic into a cat or dog. 
<img width="326" alt="SupML" src="https://user-images.githubusercontent.com/54092529/146660298-0d58cdaa-108d-4ba4-9553-938f43f3fe5e.png">

Below are the steps I have done.
1. I added new app 'Colab' in Gdrive and create new folder in Google "Colab Notebooks". Colab is a cloud environment (maintained by Google), for executing Jupyter 'notebooks'. A Jupyter notebook (.ipynb extension, 'Iron Python Notebook') is a JSON file that contains a mix of two types of "cells" - text cells that have Markdown-formatted text and images, and code cells that contain code. The code can be in Julia, Python, or R (or several other languages, including JavaScript, with appropriate language 'plugins' (kernels) installed); for this project, I used use Python notebooks.
2. Within the "Colab Notebooks" folder, I created a folder called "cats-vs-dogs". Now NN needed DATA [images of cats and dogs] for training and validation, and scripts for training+validation and classifying. There are "data" folder in  my github, in the train/ folder contains 1000 images of cats under "cats", and 1000 images of dog ones in "dogs". Obviously, you know which is which. A neural network trained from scratch, and learn the difference, just based on these 2000 'training dataset' images. The validation/ folder contains 400 images each, of more cats and dogs - these are to feed the trained network, compare its classification answers to the actual answers so we can compute the accuracy of the training (in the code, it do this after each training epoch, to watch the accuracy build up). And, live/ is where I placed new (to the NN) images of cats and dogs [that are not in the training or validation datasets], and used their filenames to ask the network to classify them: an output of 0.0 means 'cat', 1.0 means 'dog'. Uploaded  data/ folder in "cats-vs-dogs" folder. 
3. There is Jupyter notebook code (train.ipynb). Uploaded it in "cats-vs-dogs" folder. The training was done using it [model.fit_generator()]. In the last line, the RESULTS [learned weights, biases, for each neuron in each layer] are stored on disk as a weights.h5 file. In order to accelerate training I used GPU but TCU will be also fast. After running it there is a report for each epoch with according accuracy. Mine is about 83%.
4. I uploaded differenet images in live and check the NN.
